{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 322]() Data Science Algorithms\n",
    "[Gonzaga University](https://www.gonzaga.edu/) |\n",
    "[Sophina Luitel](https://www.gonzaga.edu/school-of-engineering-applied-science/faculty/detail/sophina-luitel-phd-0dba6a9d)\n",
    "\n",
    "---\n",
    "\n",
    "# Ensemble Learning\n",
    "What are our learning objectives for this lesson?\n",
    "* Introduce ensemble learning\n",
    "    * Bagging\n",
    "    * Random Forests\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Dr. Gina Sprint's Data Science Algorithms notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today\n",
    "* Announcements\n",
    "    * PA6 is due today.\n",
    "    * PA7 will be posted tomorrow.\n",
    "    * Project Proposal due on Friday. So, IQ6 will be on **Monday** (17th Nov) and topics to prepare: [Measuring Classifier Performance](https://github.com/DataScienceAlgorithms/M4_MLAlgorithmsIntro/blob/main/F%20Measuring%20Classifier%20Performance.ipynb), [Decision Trees](https://github.com/DataScienceAlgorithms/M5_DecisionTrees/blob/main/A%20Decision%20Trees.ipynb) and [Attribute Selection](https://github.com/DataScienceAlgorithms/M5_DecisionTrees/blob/main/B%20Attribute%20Selection.ipynb)\n",
    "   \n",
    "* Ensemble learning  \n",
    "* Project partner finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "\n",
    "Basic Idea\n",
    "* Different (individual) classifiers have strengths and weaknesses\n",
    "* Instead of using just one, apply multiple (different) classifiers\n",
    "* Use voting to select prediction\n",
    "* Can lead to better prediction results\n",
    "\n",
    "Example\n",
    "* Entropy tends to result in smaller decision trees\n",
    "* Which often lead to \"better\" predictions ... but not guaranteed\n",
    "* Instead use different attribute selection approaches, and choose \"most popular\" prediction (among the ensemble)\n",
    "\n",
    "### Approaches to Ensemble Learning\n",
    "1. Homogeneous Ensembles (our focus)  \n",
    "    * All classifiers (base learners) are of the same type (e.g., all decision trees).\n",
    "    * Examples: Bagging, Boosting  \n",
    "\n",
    "2. Heterogeneous Ensembles  \n",
    "    * Combine different types of base learners (e.g., Decision Tree + SVM + Neural Network).\n",
    "    * Example: Stacking (Stacked Generalization)... uses a meta-model to combine predictions.\n",
    "\n",
    "There are multiple ways to generate a large number of classifiers (e.g., 100) from a dataset. You can either use all of them in the ensemble or select a subset based on performance or diversity.\n",
    "\n",
    "Techniques we will look into:\n",
    "* Bagging (Bootstrap Aggregation)\n",
    "* Random Forests \n",
    "\n",
    "Different possible voting schemes for combining ensemble results\n",
    "* (Simple) Majority voting\n",
    "* Weighted voting\n",
    "* Track record voting\n",
    "\n",
    "### Bagging (Bootstrap Aggregation)\n",
    "Recall: Bootstrap method performs sampling with replacement\n",
    "* Given a dataset $D$ of size $|D|$ instances\n",
    "* Randomly select $|D|$ instances with replacement\n",
    "* On average, about 63% of the original instances appear in the training set, while the remaining ~37% form the test set.\n",
    "* Training set will (likely) have duplicates\n",
    "\n",
    "Basic Idea\n",
    "* Generate $k$ classifiers\n",
    "* Each classifier $M_i$ is trained on $D_i$ (for $1 \\leq i \\leq k$)\n",
    "* Where $D_i$ is a bootstrap sample\n",
    "\n",
    "To classify an instance $X$:\n",
    "* Run each classifier $M_i$ on X to get predicted label $L_i$\n",
    "* Each label $L_i$ is a vote for that label\n",
    "* Use the majority label (i.e., the mode) as the prediction\n",
    "\n",
    "### Lab Task 1\n",
    "Write a bootstrap function to return a random sample of rows with\n",
    "replacement.\n",
    "\n",
    "\n",
    "\n",
    "Note that instead of using bootstrapping for testing, \n",
    "* We are using it here to **create** the ensemble for prediction\n",
    "* i.e., our classifier = set of classifiers over subsamples of original dataset\n",
    "* We are not using bootstrapping for testing in this case\n",
    "\n",
    "Some advantages of bagging (bootstrap aggregation)\n",
    "* Simple idea, simple to implement\n",
    "* Can help deal with overfitting and noisy data (outliers)\n",
    "* Can increase accuracy by reducing variance of individual classifiers\n",
    "\n",
    "### Random Forests\n",
    "Basic Idea\n",
    "* Generate many different decision trees (a \"forest\" of trees) ... $N$ trees\n",
    "\n",
    "Q: What are ways we could do this?\n",
    "* Use bagging (bootstrap aggregation)\n",
    "* Randomly select attributes (many possible trees!)\n",
    "* Use different attribute selection approaches (Entropy, GINI, ...)\n",
    "* Use a subset of attributes for each tree\n",
    "* And so on\n",
    "\n",
    "Random Forests approach:\n",
    "* Build each tree using bagging (so different data sample used for each tree)\n",
    "* At each node, select attribute from a random subset of available attributes... subset size $F$\n",
    "* Use entropy to select attribute to (split) partition on\n",
    "* Select the \"best\" subset of random trees to use in ensemble ... $M \\subset N$\n",
    "\n",
    "Note that $N$, $M$, and $F$ are all hyperparameters of the algorithm, which are set before training and can be tuned to improve performance.\n",
    "\n",
    "### Lab Task 2\n",
    "Define a python function that selects F random attributes from an attribute list.\n",
    "\n",
    "\n",
    "### The Random Forest Procedure\n",
    "1. Divide $D$ into a test and remainder set\n",
    "    * Take 1/3 for test set, 2/3 for remainder set\n",
    "    * Ensure test set has same distribution of class labels as $D$ (\"stratified\")\n",
    "    * Randomly select instances when generating test set\n",
    "2. Create $N$ bootstrap samples from remainder set\n",
    "    * Each results in a **training** (63%) and **validation** (~37%) set\n",
    "    * Build and test a classifier for each of the N bootstrap samples\n",
    "    * Each classifier is a decision tree using $F$-sized random attribute subsets\n",
    "    * Determine accuracy of classifier using validation set\n",
    "3. Pick the $M$ best classifiers generated in step 2\n",
    "4. Use test set from step 1 to determine performance of the ensemble of $M$ classifiers (using simple majority voting)\n",
    "\n",
    "Again note: $N$, $M$, and $F$ are hyperparameters, which are set before training and can be tuned to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (For Extra Practice)\n",
    "Assume we have a dataset with 4 attributes ($a_1$, $a_2$, $a_3$, $a_4$) where each attribute has two possible values ($v_1$ and $v_2$) and attribute $a_5$ contains class labels with two possible values ($yes$ and $no$). Using random attribute subsets of size 2:\n",
    "1. Give an example of a complete decision tree that could be generated using the random forest approach\n",
    "1. Show the random attribute subset for each attribute node in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
